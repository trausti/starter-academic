@incollection{scholkopf_single_2007,
 abstract = {Human listeners have the extraordinary ability to hear and recognize speech even when more than one person is talking. Their machine counterparts have historically been unable to compete with this ability, until now. We present a modelbased system that performs on par with humans in the task of separating speech of two talkers from a single-channel recording. Remarkably, the system surpasses human recognition performance in many conditions. The models of speech use temporal dynamics to help infer the source speech signals, given mixed speech signals. The estimated source signals are then recognized using a conventional speech recognition system. We demonstrate that the system achieves its best performance when the model of temporal dynamics closely captures the grammatical constraints of the task.},
 booktitle = {Advances in Neural Information Processing Systems 19},
 doi = {10.7551/mitpress/7503.003.0079},
 editor = {Schölkopf, Bernhard and Platt, John and Hofmann, Thomas},
 file = {Schölkopf et al. - 2007 - Single Channel Speech Separation Using Factorial D.pdf:/Users/trausti/Zotero/storage/6CUCY3UW/Schölkopf et al. - 2007 - Single Channel Speech Separation Using Factorial D.pdf:application/pdf},
 isbn = {978-0-262-25691-9},
 language = {en},
 publisher = {The MIT Press},
 title = {Single Channel Speech Separation Using Factorial Dynamics},
 url = {https://direct.mit.edu/books/book/3168/chapter/87461/single-channel-speech-separation-using-factorial},
 urldate = {2021-05-19},
 year = {2007}
}

