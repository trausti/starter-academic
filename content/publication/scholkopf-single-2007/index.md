---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Single Channel Speech Separation Using Factorial Dynamics
subtitle: ''
summary: ''
authors:
- Bernhard Sch√∂lkopf
- John Platt
- Thomas Hofmann
tags: []
categories: []
date: '2007-01-01'
lastmod: 2021-05-19T04:58:07-07:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-05-19T11:58:07.097045Z'
publication_types:
- '6'
abstract: Human listeners have the extraordinary ability to hear and recognize speech
  even when more than one person is talking. Their machine counterparts have historically
  been unable to compete with this ability, until now. We present a modelbased system
  that performs on par with humans in the task of separating speech of two talkers
  from a single-channel recording. Remarkably, the system surpasses human recognition
  performance in many conditions. The models of speech use temporal dynamics to help
  infer the source speech signals, given mixed speech signals. The estimated source
  signals are then recognized using a conventional speech recognition system. We demonstrate
  that the system achieves its best performance when the model of temporal dynamics
  closely captures the grammatical constraints of the task.
publication: '*Advances in Neural Information Processing Systems 19*'
url_pdf: https://direct.mit.edu/books/book/3168/chapter/87461/single-channel-speech-separation-using-factorial
doi: 10.7551/mitpress/7503.003.0079
---
