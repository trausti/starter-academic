@article{hershey_super-human_2010,
 abstract = {We present a system that can separate and recognize the simultaneous speech of two people recorded in a single channel. Applied to the monaural speech separation and recognition challenge, the system out-performed all other participants – including human listeners – with an overall recognition error rate of 21.6%, compared to the human error rate of 22.3%. The system consists of a speaker recognizer, a model-based speech separation module, and a speech recognizer. For the separation models we explored a range of speech models that incorporate diﬀerent levels of constraints on temporal dynamics to help infer the source speech signals. The system achieves its best performance when the model of temporal dynamics closely captures the grammatical constraints of the task. For inference, we compare a 2-D Viterbi algorithm and two loopy belief-propagation algorithms. We show how belief-propagation reduces the complexity of temporal inference from exponential to linear in the number of sources and the size of the language model. The best belief-propagation method results in nearly the same recognition error rate as exact inference.},
 author = {Hershey, John R. and Rennie, Steven J. and Olsen, Peder A. and Kristjansson, Trausti T.},
 doi = {10.1016/j.csl.2008.11.001},
 file = {Hershey et al. - 2010 - Super-human multi-talker speech recognition A gra.pdf:/Users/trausti/Zotero/storage/VVEBMQT6/Hershey et al. - 2010 - Super-human multi-talker speech recognition A gra.pdf:application/pdf},
 issn = {08852308},
 journal = {Computer Speech & Language},
 language = {en},
 month = {January},
 number = {1},
 pages = {45--66},
 shorttitle = {Super-human multi-talker speech recognition},
 title = {Super-human multi-talker speech recognition: A graphical modeling approach},
 url = {https://linkinghub.elsevier.com/retrieve/pii/S0885230808000557},
 urldate = {2021-05-19},
 volume = {24},
 year = {2010}
}

