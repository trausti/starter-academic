---
# Documentation: https://wowchemy.com/docs/managing-content/

title: Multichannel Audio Front-End for Far-Field Automatic Speech Recognition
subtitle: ''
summary: ''
authors:
- Amit Chhetri
- Philip Hilmes
- Trausti Kristjansson
- Wai Chu
- Mohamed Mansour
- Xiaoxue Li
- Xianxian Zhang
tags: []
categories: []
date: '2018-09-01'
lastmod: 2021-05-19T04:58:11-07:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2021-05-19T11:58:10.995209Z'
publication_types:
- '1'
abstract: Far-ﬁeld automatic speech recognition (ASR) is a key enabling technology
  that allows untethered and natural voice interaction between users and Amazon Echo
  family of products. A key component in realizing far-ﬁeld ASR on these products
  is the suite of audio front-end (AFE) algorithms that helps in mitigating acoustic
  environmental challenges and thereby improving the ASR performance. In this paper,
  we discuss the key algorithms within the AFE, and we provide insights into how these
  algorithms help in mitigating the various acoustical challenges for far-ﬁeld processing.
  We also provide insights into the audio algorithm architecture adopted for the AFE,
  and we discuss ongoing and future research.
publication: '*2018 26th European Signal Processing Conference (EUSIPCO)*'
url_pdf: https://ieeexplore.ieee.org/document/8553149/
doi: 10.23919/EUSIPCO.2018.8553149
---
